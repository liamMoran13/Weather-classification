{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the training, validation, and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_training = pd.read_csv('training_data.csv',index_col=[0])\n",
    "raw_valid = pd.read_csv('valid_data.csv',index_col=[0])\n",
    "raw_test = pd.read_csv('test_data.csv',index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List_of_changes for pipeline <br>\n",
    "1. Add temp more than feels like <br>\n",
    "2. Drop preciptype, precipprob, severerisk, and description, icon, stations,tempmin,tempmax,temp,feelslikemax,feelslikemin,feelslike <br>\n",
    "3. Add if precipcover is over 75 <br>\n",
    "4.Scale features <br> \n",
    "5. Most important: cloudcover, humidity <br>\n",
    "6. Convert sunset and sunrise\n",
    "7. Create number of conditions column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_training['feels_more_than_actual'] = raw_training['feelslike'] - raw_training['temp']\n",
    "raw_training['range_of_temp'] = raw_training['tempmax'] - raw_training['tempmin']\n",
    "raw_valid['feels_more_than_actual'] = raw_valid['feelslike'] - raw_valid['temp']\n",
    "raw_valid['range_of_temp'] = raw_valid['tempmax'] - raw_valid['tempmin']\n",
    "raw_test['feels_more_than_actual'] = raw_test['feelslike'] - raw_test['temp']\n",
    "raw_test['range_of_temp'] = raw_test['tempmax'] - raw_test['tempmin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_training.drop(['preciptype','precipprob','severerisk','description','icon','stations','tempmin','tempmax','temp','feelslikemax','feelslikemin','feelslike'],axis=1, inplace=True)\n",
    "raw_valid.drop(['preciptype','precipprob','severerisk','description','icon','stations','tempmin','tempmax','temp','feelslikemax','feelslikemin','feelslike'],axis=1, inplace=True)\n",
    "raw_test.drop(['preciptype','precipprob','severerisk','description','icon','stations','tempmin','tempmax','temp','feelslikemax','feelslikemin','feelslike'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_training['mostly_raining'] = raw_training['precipcover'].apply(lambda x: 1 if x>75 else 0)\n",
    "raw_valid['mostly_raining'] = raw_valid['precipcover'].apply(lambda x: 1 if x>75 else 0)\n",
    "raw_test['mostly_raining'] = raw_test['precipcover'].apply(lambda x: 1 if x>75 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_training.drop(['precipcover'],axis=1,inplace=True)\n",
    "raw_valid.drop(['precipcover'],axis=1, inplace=True)\n",
    "raw_test.drop(['precipcover'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_training['sunrise'] = raw_training['sunrise'].apply(lambda x: x[-5:])\n",
    "raw_training['sunrise'] = raw_training['sunrise'].apply(lambda x: '0'+x if len(x)==4 else x)\n",
    "raw_training['sunrise'] = raw_training['sunrise'].apply(lambda x: str(int(x[:2])-24)+x[-3:] if int(x[:2]) >= 24 else x)\n",
    "raw_training['sunrise'] = pd.to_datetime(raw_training['sunrise']).dt.strftime('%H:%M')\n",
    "\n",
    "raw_valid['sunrise'] = raw_valid['sunrise'].apply(lambda x: x[-5:])\n",
    "raw_valid['sunrise'] = raw_valid['sunrise'].apply(lambda x: '0'+x if len(x)==4 else x)\n",
    "raw_valid['sunrise'] = raw_valid['sunrise'].apply(lambda x: str(int(x[:2])-24)+x[-3:] if int(x[:2]) >= 24 else x)\n",
    "raw_valid['sunrise'] = pd.to_datetime(raw_valid['sunrise']).dt.strftime('%H:%M')\n",
    "\n",
    "raw_test['sunrise'] = raw_test['sunrise'].apply(lambda x: x[-5:])\n",
    "raw_test['sunrise'] = raw_test['sunrise'].apply(lambda x: '0'+x if len(x)==4 else x)\n",
    "raw_test['sunrise'] = raw_test['sunrise'].apply(lambda x: str(int(x[:2])-24)+x[-3:] if int(x[:2]) >= 24 else x)\n",
    "raw_test['sunrise'] = pd.to_datetime(raw_test['sunrise']).dt.strftime('%H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_training['sunset'] = raw_training['sunset'].apply(lambda x: x[-5:])\n",
    "raw_training['sunset'] = raw_training['sunset'].apply(lambda x: '0'+x if len(x)==4 else x)\n",
    "raw_training['sunset'] = raw_training['sunset'].apply(lambda x: str(int(x[:2])-24)+x[-3:] if int(x[:2]) >= 24 else x)\n",
    "raw_training['sunset'] = pd.to_datetime(raw_training['sunset']).dt.strftime('%H:%M')\n",
    "\n",
    "raw_valid['sunset'] = raw_valid['sunset'].apply(lambda x: x[-5:])\n",
    "raw_valid['sunset'] = raw_valid['sunset'].apply(lambda x: '0'+x if len(x)==4 else x)\n",
    "raw_valid['sunset'] = raw_valid['sunset'].apply(lambda x: str(int(x[:2])-24)+x[-3:] if int(x[:2]) >= 24 else x)\n",
    "raw_valid['sunset'] = pd.to_datetime(raw_valid['sunset']).dt.strftime('%H:%M')\n",
    "\n",
    "raw_test['sunset'] = raw_test['sunset'].apply(lambda x: x[-5:])\n",
    "raw_test['sunset'] = raw_test['sunset'].apply(lambda x: '0'+x if len(x)==4 else x)\n",
    "raw_test['sunset'] = raw_test['sunset'].apply(lambda x: str(int(x[:2])-24)+x[-3:] if int(x[:2]) >= 24 else x)\n",
    "raw_test['sunset'] = pd.to_datetime(raw_test['sunset']).dt.strftime('%H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['sunrise_minutes'] = X_train['sunrise'].apply(lambda x: int(x[:2])*60+int(x[-2:]))\n",
    "X_valid['sunrise_minutes'] = X_valid['sunrise'].apply(lambda x: int(x[:2])*60+int(x[-2:]))\n",
    "X_test['sunrise_minutes'] = X_test['sunrise'].apply(lambda x: int(x[:2])*60+int(x[-2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['sunset_minutes'] = X_train['sunset'].apply(lambda x: int(x[:2])*60+int(x[-2:]))\n",
    "X_valid['sunset_minutes'] = X_valid['sunset'].apply(lambda x: int(x[:2])*60+int(x[-2:]))\n",
    "X_test['sunset_minutes'] = X_test['sunset'].apply(lambda x: int(x[:2])*60+int(x[-2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_training['conditions'] = raw_training['conditions'].apply(lambda x: len(x.split(',')))\n",
    "raw_valid['conditions'] = raw_valid['conditions'].apply(lambda x: len(x.split(',')))\n",
    "raw_test['conditions'] = raw_test['conditions'].apply(lambda x: len(x.split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.drop(['name','datetime'],inplace=True,axis=1)\n",
    "X_valid.drop(['name','datetime'],inplace=True,axis=1)\n",
    "X_test.drop(['name','datetime'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_training.reset_index(drop=True,inplace=True)\n",
    "raw_valid.reset_index(drop=True,inplace=True)\n",
    "raw_test.reset_index(drop=True,inplace=True)\n",
    "\n",
    "y_train = raw_training['target']\n",
    "X_train = raw_training.drop(['target'],inplace=True,axis=1)\n",
    "y_valid = raw_valid['target']\n",
    "X_valid = raw_valid.drop(['target'],inplace=True,axis=1)\n",
    "y_test = raw_test['target']\n",
    "X_test = raw_test.drop(['target'],inplace=True,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['sunset','sunrise'],inplace=True,axis=1)\n",
    "X_valid.drop(['sunset','sunrise'],inplace=True,axis=1)\n",
    "X_test.drop(['sunset','sunrise'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "imputer = SimpleImputer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = imputer.fit_transform(X_train)\n",
    "X_valid = imputer.transform(X_valid)\n",
    "X_test = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype('category')\n",
    "#df['target'] = df['target'].astype('object')\n",
    "y_valid = y_valid.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_valid_poly = poly.fit_transform(X_valid)\n",
    "X_test_poly = poly.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = LogisticRegression()\n",
    "linear_model_poly = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49194414607948445"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_valid,linear_model.predict(X_valid))\n",
    "f1_score(y_valid,linear_model_poly.predict(X_valid_poly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get baseline scores of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4778420038535645"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kneighbors = KNeighborsClassifier()\n",
    "kneighbors.fit(X_train,y_train)\n",
    "f1_score(y_valid,kneighbors.predict(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "k_range = list(range(20, 40))\n",
    "param_grid = dict(n_neighbors=k_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=34, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'n_neighbors': [20, 21, 22, 23, 24, 25, 26, 27, 28, 29,\n",
       "                                         30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "                                         39]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(kneighbors, param_grid, cv=10)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 34}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6665634843054197"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42382588774341357"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kneighbors = KNeighborsClassifier(n_neighbors=34)\n",
    "kneighbors.fit(X_train,y_train)\n",
    "f1_score(y_valid,kneighbors.predict(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "best_param = 0\n",
    "for i in range(1,20):\n",
    "    kneighbors = KNeighborsClassifier(n_neighbors=i)\n",
    "    kneighbors.fit(X_train,y_train)\n",
    "    current_score = f1_score(y_valid,kneighbors.predict(X_valid))\n",
    "    if current_score > best_score:\n",
    "        best_score = current_score\n",
    "        best_param = i\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best score on validation set with KKN where n_neighbors is 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4778578784757981"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets move on to Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5317460317460317"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=0)\n",
    "decision_tree.fit(X_train,y_train)\n",
    "f1_score(y_valid,decision_tree.predict(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_param = {'criterion': ['entropy','gini'], 'max_depth': [2,3,4,5,6,7,8,9],'min_samples_leaf':[1,2,3,4,5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_decision_tree = GridSearchCV(decision_tree,tree_param, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort='deprecated',\n",
       "                                              random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'criterion': ['entropy', 'gini'],\n",
       "                         'max_depth': [2, 3, 4, 5, 6, 7, 8, 9],\n",
       "                         'min_samples_leaf': [1, 2, 3, 4, 5]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_decision_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 1}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_decision_tree.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_param = {'criterion': ['entropy','gini'], 'max_depth': [2,3,4,5,6,7,8,9],'min_samples_leaf':[1,2,3,4,5],'n_estimators':[50,100,150,200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_random = GridSearchCV(random_forest,random_param,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'criterion': ['entropy', 'gini'],\n",
       "                         'max_depth': [2, 3, 4, 5, 6, 7, 8, 9],\n",
       "                         'min_samples_leaf': [1, 2, 3, 4, 5],\n",
       "                         'n_estimators': [50, 100, 150, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_random.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 4,\n",
       " 'min_samples_leaf': 3,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6933319653260195"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_random.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5139896373056996"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_valid,grid_search_random.predict(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5195071868583163"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(criterion='gini',max_depth=4,min_samples_leaf=3,n_estimators=100)\n",
    "random_forest.fit(X_train_poly,y_train)\n",
    "f1_score(y_valid,random_forest.predict(X_valid_poly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not move forward with the polynomial features because their incremental improvement on f1 is not worth the added computational complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes = BernoulliNB()\n",
    "naive_bayes.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5092322643343051"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_valid,naive_bayes.predict(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_classifier = VotingClassifier(estimators=[('nb',naive_bayes),('rf',decision_tree),('lr',linear_model)],weights=[1,.75,.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('nb',\n",
       "                              BernoulliNB(alpha=1.0, binarize=0.0,\n",
       "                                          class_prior=None, fit_prior=True)),\n",
       "                             ('rf',\n",
       "                              DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=None,\n",
       "                                                     max_features=None,\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0...\n",
       "                                                     random_state=None,\n",
       "                                                     splitter='best')),\n",
       "                             ('lr',\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='auto',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='lbfgs', tol=0.0001,\n",
       "                                                 verbose=0,\n",
       "                                                 warm_start=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=[1, 0.75, 0.75])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5185185185185186"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_valid,voting_classifier.predict(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5598086124401914"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,voting_classifier.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_model.pickle','wb') as modelfile:\n",
    "    pkl.dump(voting_classifier,modelfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
